{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From c:\\users\\aditya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\aditya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\aditya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\aditya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\aditya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\aditya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<oov>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Datasets/intents.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_x = []\n",
    "docs_y = []\n",
    "tag_list = []\n",
    "pattern_list = []\n",
    "response_list=[]\n",
    "pattern_sentence =[]\n",
    "response_sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day', 'Whats up', 'cya', 'See you later', 'Goodbye', 'I am Leaving', 'Have a Good day', 'how old', 'how old is tim', 'what is your age', 'how old are you', 'age?', 'what is your name', 'what should I call you', 'whats your name?', 'Granthium USA office', 'Granthium India office', 'Granthium UK office', 'Granthium UAE office', 'your technical parteners', 'your affiliations', 'Granthium ti-ups', 'What we do', 'What does Granthium do', 'Offerings', 'Who are you', 'your aim', 'your mission', 'domain covered', 'Telecom', 'Enterprise', 'FinTech', 'Big Data', 'IOT', 'AI-ML']\n"
     ]
    }
   ],
   "source": [
    "for intent in data['intents']:\n",
    "    tag_list.append(intent['tag'])\n",
    "    for pattern in intent['patterns']:\n",
    "        #print(pattern)\n",
    "        pattern_list.append(pattern)\n",
    "    for responses in intent['responses']:\n",
    "        response_list.append(responses)\n",
    "#print(tag_list)\n",
    "print(pattern_list)\n",
    "#print(response_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sentences in pattern_list:\n",
    "#    pattern_sentence.append(sentences)\n",
    "\n",
    "#for sentences in response_list:\n",
    "#    response_sentence.append(sentences)\n",
    "    \n",
    "#print(pattern_sentence)\n",
    "#print(response_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pattern_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "{'<oov>': 1, 'your': 2, 'granthium': 3, 'you': 4, 'what': 5, 'how': 6, 'is': 7, 'office': 8, 'are': 9, 'old': 10, 'good': 11, 'day': 12, 'whats': 13, 'i': 14, 'age': 15, 'name': 16, 'do': 17, 'hi': 18, 'anyone': 19, 'there': 20, 'hello': 21, 'up': 22, 'cya': 23, 'see': 24, 'later': 25, 'goodbye': 26, 'am': 27, 'leaving': 28, 'have': 29, 'a': 30, 'tim': 31, 'should': 32, 'call': 33, 'usa': 34, 'india': 35, 'uk': 36, 'uae': 37, 'technical': 38, 'parteners': 39, 'affiliations': 40, 'ti': 41, 'ups': 42, 'we': 43, 'does': 44, 'offerings': 45, 'who': 46, 'aim': 47, 'mission': 48, 'domain': 49, 'covered': 50, 'telecom': 51, 'enterprise': 52, 'fintech': 53, 'big': 54, 'data': 55, 'iot': 56, 'ai': 57, 'ml': 58}\n",
      "Goodbye\n",
      "[26  0  0  0  0]\n",
      "(39, 5)\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(pattern_list)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "print(word_index)\n",
    "sequences = tokenizer.texts_to_sequences(pattern_list)\n",
    "padded = pad_sequences(sequences,padding='post')\n",
    "print(pattern_list[8])\n",
    "print(padded[8])\n",
    "print(padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talking with the bot (type quit to stop)!\n",
      "You: hi\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e57ee30c65ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-5092f90acf5a>\u001b[0m in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbag_of_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mresults_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresults_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
